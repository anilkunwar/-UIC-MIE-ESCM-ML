GANs: Generative Adverserial Networks

GANS: neural networks which can generate images (also of things which do not exists)GA

Looking at the images of real objects GANS can crate images of new objects.

GANS have 2 components: 

- Generator

- Discriminator

G and D work together. Starting from scratch, they learn together.
Example: G generates images of dogs, the D looks at the images of dogs generated by G and at the images of real dogs.
The D learns what is a dog and what is not a dog and it tells to the G if the generated images of dogs are tricky enough
to discriminate. The G then learns how to generate images which are tricky enough for the D. The G learns how to create images
which can fool the D. The D in turns learns how to not be fooled by the G.

Both G and D are Neuraln Networks

gans1: the G takes in input a random noise and it generates an image.

gans2: the D takes in input the images generated by the G (fake images) and real images and it learns how to discriminate between the 2.

gans3,gans4: in the ideal world, the D has to predict probability equal to 0 for the fake images generated by G and 1 for the real images.
       If the fake images are completely random, D easily predicts 0, but during the learning process G learns how 
       to generate tricky image so D predicts probabilities higher than 0 for the images generated by G.

step1: 

gans5: training the D: the G generates an image from a random noise. The image is given in input to the D together with real images
       of dogs. The D predicts the probabilities that the input images are dogs or non-dogs. Comparing the predicted probabilities 
       with the ground truth (0 for the fake images generated by G and 1 for the real images of the dogs), the weights of the D are 
       updated with the backpropagation.
       
gans6: training the G: after training the D, the D starts to learn how to discriminate between a fake image and a real dog. 
         A fake image is given to the D and the D predicts a probability. Since the D has been previously trained, it is not completely
         inefficient in predicting if the fake image is a fake or a real dog. The D and the G are trained together. If the D was previously
         trained separately, it would predict a probaility of 0 for the fake image because it already knows that the image is a fake.
         In this case the D would be too smart to be tricked by the G. But this is not the case, so D does not predict 0, 
         but a low probability (0.1 or 0.2). 
         Then the error is calculated respect to the probability of 1. This error is backpropagated through the G, so in this way 
         the weights of the G are update in a way that it learns to generate images which are very similar to real dogs able to fool
         the D and reduce the error between the predicted probability and 1.
         

step2:

gans7: training the D: now that the D has been trained, it is able to generate fake images which are closer to real dogs and more tricky for the D.
       As in the previous step (gans5), fake images and real images are given to the D, which predicts a probaility of dog or non-dog and
       it updates the weights through backpropagation after calculating the error.
       
       
gans8: training the G: after training the D, images generated by G are given to the D, which predicts if they are dog or non-dog.
       The predicted probabilites are lower than during the training of the D, since during the training the D has already learnt 
       how to discriminate the fake images from real images. However, this probability is not 0 since the D is not perfect.
       
       IT IS IMPORTANT TO REMIND THAT IN THE TRAINING OF THE G, THE D PREDICTS PROBABILITIES FOR THE FAKE IMAGES WHICH ARE LOWER
       COMPARED TO THE PROBABILITIES PREDICTED IN THE TRAINING OF THE D,BECAUSE THE D HAS BEEN ALREADY TRAINED ON THOSE IMAGES.
       
       The D calculates the error, which is then backpropagated through the G, so the G updates the weights to generate images which 
       are more tricky for the D.
       
step3:


gans9: training the D: since the G has been trained, it is able to generate fake images which are more and more similar to real dogs.
       These images are given in input the D tegether with images of real dogs, the D is trained by predicting the probabilites, 
       calculating the error and updating the weights through backpropagation.
       
       training the G: ...
       
       
In this process the D and the G learn together: the D learns how to discriminate between fake dogs generated by the G and real dogs
and the G learns how to create tricky images which can fool the D.

gans10: the G is a Deconvolution Neural Network: it takes an input a 1D array (of random values) and it returns a 2D (the target image)
       DeconvNet have an opposite structure respect to ConvNet. 


gans11: applications of gans