{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook it is shown how to train the neural network on the simulated HRTEM images generated with make_training_data.py. The neural network is trained for many epochs and in each epoch the set of weights is saved in a dedicated folder. The training is performed on batches of images, and the model's parameters (weights and bias) are update using the gradient descent and backpropagation algorithm. \n",
    "The performance of the training is evaluated by computing the R2 score between the predicted and the true heights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.utils import multi_gpu_model\n",
    "from net_architecture import CNN\n",
    "from data_preparation import DataSet,DataEntry,load,get_data,Training_Data_Generator\n",
    "from performance import performance_CH,get_performance_on_batch_train\n",
    "import os\n",
    "from datetime import datetime\n",
    "import platform\n",
    "import sys\n",
    "import time\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model:\n",
    "\n",
    "- input_channel=1: the HRTEM images are simulated with a single defocus value.\n",
    "- input_shape=(256,256): image size.\n",
    "- output channel=1: only a single output class is present in the regression scheme. In a standard semantic segmenatation procedure, the output channel is >1, corresponding to the number of classes to predict. In the classification model we have described in the manuscript and it is not present here, we have considered a total of 16 classes corresponding to column heights ranging from 1 to 16.\n",
    "\n",
    "The model can be in serial or parallel mode depending on the gpus available on the user's machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channel=1\n",
    "input_shape=(256,256)\n",
    "input_tensor = keras.Input(shape=input_shape+(input_channel,))\n",
    "output_channel=1\n",
    "serial_model=CNN(input_tensor,output_channels=output_channel)\n",
    "\n",
    "numgpus = 1\n",
    "\n",
    "if numgpus >1:\n",
    "    model=multi_gpu_model(serial_model,gpus=numgpus)\n",
    "else:\n",
    "    model=serial_model\n",
    "model.compile(optimizer='adam', loss='mse',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training data from folder. The folder 'data/training/' contains 2 subfolder: 'images' and 'labels' which contain the simulated HRTEM image and the corresponding labels generated with make_training_data.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path='data/training/'\n",
    "training_data=load(training_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a generator of training batches. Here a batch size of 2 is adopted (the weights and the bias are update with a 2 images training), but this value can be changed depending on the user's needs. A batch training corresponds to a step of the epoch. The total number of steps in an epoch is equal to the number of training images divided by the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=2\n",
    "training_data_generator=Training_Data_Generator(training_data,batch_size)\n",
    "num_training_data=training_data.num_examples\n",
    "steps_per_epoch=num_training_data//batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here a total number of 50 epoch is defined, but this value can be changed by the user. At each epoch the set of weights is saved in the folder 'weights/trained_weights/'. In this way, the weights can be loaded in test model to evaluate the performance of the neural network on unseen images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=50\n",
    "total_num_steps=num_epochs*steps_per_epoch\n",
    "weights_folder_path='weights/trained_weights/epoch-{}.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the lists to save the metrics of the model for each epoch. The performance of the model is evaluated on each single image, then an average of all the images contained in a batch is calculated to obtain the performance in a single batch. Then, the average of the performance of all the batches is calculated to obtaine the performance in a single epoch. This value is saved in the dedicated list shown in the cell below. Here we consider the loss (mean squared error 'mse', the accuracy and R2 between the predicted and the true heights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_all_epochs=[]\n",
    "accuracy_all_epochs=[]\n",
    "r2_heights_all_epochs=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training takes action\n",
      "Training on 2 images in the batch.\n",
      "\n",
      "WARNING:tensorflow:From /home/mragon2/softwares/anaconda3/envs/atomistic/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mragon2/softwares/anaconda3/envs/atomistic/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch: 0/50 Batch: 0/11   [0/1100]\n",
      "\n",
      "Training on 2 images in the batch.\n",
      "\n",
      "Epoch: 0/50 Batch: 1/11   [2/1100]\n",
      "\n",
      "Training on 2 images in the batch.\n",
      "\n",
      "Epoch: 0/50 Batch: 2/11   [4/1100]\n",
      "\n",
      "Training on 2 images in the batch.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Beginning of training\n",
    "\n",
    "print('Training takes action')\n",
    "before = time.time()\n",
    "\n",
    "# for loop over the epochs\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # define the lists containg the performance in each training step in an epoch\n",
    "    loss_in_steps=[]\n",
    "    accuracy_in_steps=[]\n",
    "    r2_heights_in_steps=[]\n",
    "    \n",
    "    # for loop over the training steps\n",
    "    for i in range(steps_per_epoch):\n",
    "        \n",
    "        # lists corresponding to a batch of images and labels\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "           \n",
    "        # load the batch\n",
    "        for b in range(batch_size):\n",
    "            # generation of the training images and labels\n",
    "            img, lbl = training_data_generator.next_example()\n",
    "            \n",
    "            # populating the images and labels batches\n",
    "            batch_images.append(img)\n",
    "            batch_labels.append(lbl)\n",
    "        batch_images = np.concatenate(batch_images)\n",
    "        batch_labels = np.concatenate(batch_labels)\n",
    "        \n",
    "        # training of the model in a batch of images\n",
    "        performance_in_batch=model.train_on_batch(batch_images, batch_labels)\n",
    "            \n",
    "        # evaluating the model training on the batch\n",
    "        loss_in_batch=performance_in_batch[0]\n",
    "        accuracy_in_batch=performance_in_batch[1]\n",
    "        \n",
    "        # the R2 between the predicted and the true heights is calculated using the function\n",
    "        # 'get_performance_on_batch_train' defined in the 'perforamance.py' file.\n",
    "        r2_heights_in_batch=get_performance_on_batch_train(model,batch_images,batch_labels,batch_size)\n",
    "            \n",
    "        # print the step of the learning process\n",
    "        print(\"Epoch: {}/{} Batch: {}/{}   [{}/{}]\".format(epoch, num_epochs,\n",
    "                                                                   i, steps_per_epoch,\n",
    "                                                                   (i + epoch*steps_per_epoch)*batch_size,\n",
    "                                                                   total_num_steps*batch_size),flush=True)\n",
    "        print('')\n",
    "        \n",
    "    \n",
    "            \n",
    "            \n",
    "           \n",
    "        # populating the lists containing the performance on each batch\n",
    "        loss_in_steps.append(loss_in_batch)\n",
    "        accuracy_in_steps.append(accuracy_in_batch)\n",
    "        r2_heights_in_steps.append(r2_heights_in_batch)\n",
    "\n",
    "            \n",
    "    # calculating the mean value of the performance in all the batch\n",
    "    # the obtained value is considered as the performance in the epoch\n",
    "    loss_in_epoch=np.mean(np.array(loss_in_steps))\n",
    "    accuracy_in_epoch=np.mean(np.array(accuracy_in_steps))\n",
    "    r2_heights_in_epoch=np.mean(np.array(r2_heights_in_steps))\n",
    "        \n",
    "    # print the R2 score\n",
    "    print('r2 in epoch ' +str(epoch)+': '+str(r2_heights_in_epoch))\n",
    "    print('')\n",
    "    print('')\n",
    "    \n",
    "    # populating the lists containg the performance of each epoch\n",
    "    loss_all_epochs.append(loss_in_epoch)\n",
    "    accuracy_all_epochs.append(accuracy_in_epoch)\n",
    "    r2_heights_all_epochs.append(r2_heights_in_epoch)\n",
    "        \n",
    "    # saving the weights of the current epoch\n",
    "    model.save_weights(weights_folder_path.format(epoch))\n",
    "\n",
    "# turning the lists containing the performance of each epoch in a numpy array\n",
    "loss_all_epochs=np.array(loss_all_epochs)\n",
    "accuracy_all_epochs=np.array(accuracy_all_epochs)\n",
    "r2_heights_all_epochs=np.array(r2_heights_all_epochs)\n",
    "    \n",
    "# saving the arrays containing the performance of each epoch in the folder 'save_performance/training/'\n",
    "np.save('save_performance/training/loss_all_epochs.npy',loss_all_epochs)\n",
    "np.save('save_performance/training/accuracy_all_epochs.npy',accuracy_all_epochs)\n",
    "np.save('save_performance/training/accuracy_all_epochs.npy',r2_heights_all_epochs)\n",
    " \n",
    "    \n",
    "totaltime = time.time() - before\n",
    "print('Processing time : {} sec  ({} hours)'.format(totaltime, totaltime/3600))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
